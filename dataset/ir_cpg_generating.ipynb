{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from utils import generate_ir_and_cpg, cpg_dot2json\n",
    "import shutil\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llvm2cpg developed by Joern requires LLVM 11\n",
    "os.putenv(\"PATH\", \"/usr/bin:/usr/local/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_vul_preprocessed_path = \"big_vul_preprocessed.zip\"\n",
    "big_vul_df = pd.read_pickle(big_vul_preprocessed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_vul_df.loc[:, 'func_name'] = big_vul_df['func_name'].apply(lambda x: np.nan if len(x) == 0 or x == 'null' else x)\n",
    "big_vul_df = big_vul_df.dropna(subset=\"func_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating compilication args per repo: 100%|██████████| 413/413 [11:11<00:00,  1.63s/it]  \n"
     ]
    }
   ],
   "source": [
    "generate_ir_and_cpg_args = []\n",
    "for code_link in tqdm(big_vul_df[\"code_link\"].unique().tolist(), desc='Generating compilication args per repo'):\n",
    "    project_df = big_vul_df[big_vul_df.code_link == code_link]\n",
    "    repo_dir_name = \"_\".join(code_link.split(\".git\")[0].split(\"//\")[1].split(\"/\")[1:])\n",
    "    result_dir_name = repo_dir_name\n",
    "    i = 1\n",
    "    for version_pair in project_df[[\"project_before\", \"project_after\"]].drop_duplicates().itertuples():\n",
    "        project_per_version_pair_df = project_df[project_df.apply(\n",
    "            func=lambda x: True if x.project_before == version_pair.project_before and x.project_after == version_pair.project_after else False,\n",
    "            axis=1\n",
    "        )]\n",
    "        function_list = [function for function in project_per_version_pair_df[\"func_name\"].tolist() if function.find(\"::\") == -1]\n",
    "        if len(function_list) == 0:\n",
    "            continue\n",
    "        generate_ir_and_cpg_args.append((code_link, f\"{repo_dir_name}_{i}\", result_dir_name, {\n",
    "            version_pair.project_before: function_list,\n",
    "            version_pair.project_after: function_list\n",
    "        }))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ir_and_cpg_args.sort(key=lambda x: len(x[3][list(x[3].keys())[0]]))\n",
    "with open(f\"generate_ir_and_cpg_args.json\", \"w+\") as f:\n",
    "    f.write(json.dumps(generate_ir_and_cpg_args, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"generate_ir_and_cpg_args.json\", \"r\") as f:\n",
    "    generate_ir_and_cpg_args = json.load(f)\n",
    "\n",
    "generate_ir_and_cpg_args = [(project[0], project[1], project[2], project[3]) for project in generate_ir_and_cpg_args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_projects = ['chromium_chromium', 'drm_drm-misc', 'chrisd1100_uncurl', 'torvalds_linux']\n",
    "filtered_generate_ir_and_cpg_args = [args for args in generate_ir_and_cpg_args if args[2] not in filtered_projects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"error_dump\"):\n",
    "    os.mkdir(\"error_dump\")\n",
    "else:\n",
    "    shutil.rmtree(\"error_dump\")\n",
    "    os.mkdir(\"error_dump\")\n",
    "\n",
    "if not os.path.exists(\"repo_clone\"):\n",
    "    os.mkdir(\"repo_clone\")\n",
    "else:\n",
    "    shutil.rmtree(\"repo_clone\")\n",
    "    os.mkdir(\"repo_clone\")\n",
    "\n",
    "with Pool(processes=24) as pool:\n",
    "    list(tqdm(pool.imap_unordered(generate_ir_and_cpg, filtered_generate_ir_and_cpg_args), total=len(filtered_generate_ir_and_cpg_args), desc='Compiling for LLVM IRs and generating CPGs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerun = [\n",
    "    \n",
    "]\n",
    "rerun_args = [args for args in filtered_generate_ir_and_cpg_args if args[2] in rerun]\n",
    "\n",
    "if not os.path.exists(\"error_dump\"):\n",
    "    os.mkdir(\"error_dump\")\n",
    "else:\n",
    "    shutil.rmtree(\"error_dump\")\n",
    "    os.mkdir(\"error_dump\")\n",
    "\n",
    "if not os.path.exists(\"repo_clone\"):\n",
    "    os.mkdir(\"repo_clone\")\n",
    "else:\n",
    "    shutil.rmtree(\"repo_clone\")\n",
    "    os.mkdir(\"repo_clone\")\n",
    "\n",
    "with Pool(processes=4) as pool:\n",
    "    list(tqdm(pool.imap_unordered(generate_ir_and_cpg, rerun_args), total=len(rerun_args)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding generated LLVM IRs and CPGs to the dataset: 100%|██████████| 413/413 [04:56<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for code_link in tqdm(big_vul_df[\"code_link\"].unique().tolist(), desc='Adding generated LLVM IRs and CPGs to the dataset'):\n",
    "    project_df = big_vul_df[big_vul_df.code_link == code_link]\n",
    "    repo_name = \"_\".join(code_link.split(\".git\")[0].split(\"//\")[1].split(\"/\")[1:])\n",
    "    \n",
    "    if os.path.exists(f\"./llvm_ir/{repo_name}\") or os.path.exists(f\"./cpg/{repo_name}\"):\n",
    "        for version_pair in project_df[[\"project_before\", \"project_after\"]].drop_duplicates().itertuples():\n",
    "            project_per_version_pair_df = project_df[project_df.apply(\n",
    "                func=lambda x: True if x.project_before == version_pair.project_before and x.project_after == version_pair.project_after else False,\n",
    "                axis=1\n",
    "            )]\n",
    "            \n",
    "            for id in project_per_version_pair_df.index.tolist():\n",
    "                if os.path.exists(f\"./llvm_ir/{repo_name}/{version_pair.project_before}/{big_vul_df.loc[id, 'func_name']}.ll\"):\n",
    "                    with open(f\"./llvm_ir/{repo_name}/{version_pair.project_before}/{big_vul_df.loc[id, 'func_name']}.ll\", \"r\") as llvm_ir_file:\n",
    "                        big_vul_df.loc[id, \"llvm_ir_before\"] = llvm_ir_file.read()\n",
    "                \n",
    "                if os.path.exists(f\"./llvm_ir/{repo_name}/{version_pair.project_after}/{big_vul_df.loc[id, 'func_name']}.ll\"):\n",
    "                    with open(f\"./llvm_ir/{repo_name}/{version_pair.project_after}/{big_vul_df.loc[id, 'func_name']}.ll\", \"r\") as llvm_ir_file:\n",
    "                        big_vul_df.loc[id, \"llvm_ir_after\"] = llvm_ir_file.read()\n",
    "                \n",
    "                if os.path.exists(f\"./cpg/{repo_name}/{version_pair.project_before}/{big_vul_df.loc[id, 'func_name']}.json\"):\n",
    "                    with open(f\"./cpg/{repo_name}/{version_pair.project_before}/{big_vul_df.loc[id, 'func_name']}.json\", \"r\") as cpg_file:\n",
    "                        cpg_list = json.load(cpg_file)\n",
    "                        if len(cpg_list) == 0:\n",
    "                            continue\n",
    "                        if len(cpg_list) == 1:\n",
    "                            big_vul_df.loc[id, \"cpg\"] = cpg_list[0]\n",
    "                            continue\n",
    "                        big_vul_df.loc[id, \"cpg\"] = max(cpg_list, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpg_df = big_vul_df[big_vul_df.cpg.notna()]\n",
    "cpg_df = cpg_df[cpg_df.llvm_ir_before.notna()]\n",
    "cpg_df = cpg_df[cpg_df.apply(lambda x: False if x['llvm_ir_before'] == x['llvm_ir_after'] and x['vul'] == 1 else True, axis=1)]\n",
    "cpg_df['cpg'] = cpg_df['cpg'].apply(lambda x: cpg_dot2json(x, json_format=True))\n",
    "cpg_df.reset_index(drop=True, inplace=True)\n",
    "cpg_df.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vul\n",
       "0    23709\n",
       "1     1598\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpg_df['vul'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpg_df = cpg_df[['old_id', 'llvm_ir_before', 'llvm_ir_after', 'cpg', 'vul']]\n",
    "cpg_df.to_pickle('big_vul_ir_cpg.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, _, _ = train_test_split(cpg_df, cpg_df['vul'], train_size=int(0.8 * cpg_df.shape[0]), random_state=0)\n",
    "train_df, val_df, _, _ = train_test_split(train_df, train_df['vul'], train_size=int(0.6 * cpg_df.shape[0]), random_state=0)\n",
    "train_df_non_vul = train_df[train_df['vul'] == 0]\n",
    "train_df_non_vul = train_df_non_vul.sort_values(by='cpg', key=lambda x: x.str.len(), ignore_index=True).iloc[:int(train_df_non_vul.shape[0] * 0.75)]\n",
    "train_df_vul = train_df[train_df['vul'] == 1]\n",
    "multiplier = int(train_df_non_vul.shape[0] / train_df_vul.shape[0])\n",
    "train_df_vul_oversampled = pd.concat([train_df[train_df['vul'] == 1]] * multiplier, ignore_index=True)\n",
    "train_df = pd.concat([train_df_non_vul, train_df_vul_oversampled], ignore_index=True).sample(frac=1, random_state=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.index.name = 'id'\n",
    "test_df = test_df.reset_index().drop(columns='id')\n",
    "test_df.index.name = 'id'\n",
    "val_df = val_df.reset_index().drop(columns='id')\n",
    "val_df.index.name = 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('cpg_dataset/raw', exist_ok=True)\n",
    "os.makedirs('cpg_dataset/processed', exist_ok=True)\n",
    "\n",
    "train_df.to_pickle('cpg_dataset/raw/big_vul_ir_cpg_train.zip')\n",
    "test_df.to_pickle('cpg_dataset/raw/big_vul_ir_cpg_test.zip')\n",
    "val_df.to_pickle('cpg_dataset/raw/big_vul_ir_cpg_val.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9129f43fd07a6290ef50f4660effaeac942ad5e1f096de43341874ca54761a47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
